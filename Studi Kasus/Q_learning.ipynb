{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLnQLvvYi5C6"
      },
      "outputs": [],
      "source": [
        "#@title Define the Environment\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_states = 16\n",
        "n_actions = 4\n",
        "goal_state = 15\n",
        "\n",
        "Q_table = np.zeros((n_states, n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Hyperparameters\n",
        "learning_rate = 0.8       # α - Alpha\n",
        "discount_factor = 0.95    # γ - Gamma\n",
        "exploration_prob = 0.2    # ε - Epsilon\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "H_QQlfBxjCXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define the State Transition Function\n",
        "def get_next_state(state, action):\n",
        "    row, col = divmod(state, 4)\n",
        "\n",
        "    if action == 0 and col > 0:\n",
        "        col -= 1\n",
        "    elif action == 1 and col < 3:\n",
        "        col += 1\n",
        "    elif action == 2 and row > 0:\n",
        "        row -= 1\n",
        "    elif action == 3 and row < 3:\n",
        "        row += 1\n",
        "\n",
        "    return row * 4 + col"
      ],
      "metadata": {
        "id": "3PjBfePejEVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Implement the Q-Learning Algorithm\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    current_state = np.random.randint(0, n_states)\n",
        "\n",
        "    while True:\n",
        "        if np.random.rand() < exploration_prob:\n",
        "            action = np.random.randint(0, n_actions)\n",
        "        else:\n",
        "            action = np.argmax(Q_table[current_state])\n",
        "\n",
        "        next_state = get_next_state(current_state, action)\n",
        "\n",
        "        reward = 1 if next_state == goal_state else 0  # Kalau next_state == 15 (goal) reward = 1, Kalau belum sampai goal reward = 0\n",
        "\n",
        "        Q_table[current_state, action] += learning_rate * (\n",
        "            reward + discount_factor * np.max(Q_table[next_state]) - Q_table[current_state, action]\n",
        "        )\n",
        "\n",
        "        if next_state == goal_state:\n",
        "            break\n",
        "\n",
        "        current_state = next_state"
      ],
      "metadata": {
        "id": "NYoM2g5rjGsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output the Learned Q-Table\n",
        "\n",
        "q_values_grid = np.max(Q_table, axis=1).reshape((4, 4))\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(q_values_grid, cmap='coolwarm', interpolation='nearest')\n",
        "plt.colorbar(label='Q-value')\n",
        "plt.title('Learned Q-values for Each State')\n",
        "plt.xticks(np.arange(4), ['0', '1', '2', '3'])\n",
        "plt.yticks(np.arange(4), ['0', '1', '2', '3'])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(True)\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        plt.text(j, i, f'{q_values_grid[i, j]:.2f}', ha='center', va='center', color='black')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"Learned Q-table:\")\n",
        "print(Q_table)\n",
        "\n",
        "# Merah/Merah Tua (16.5-17.0) = Q-value SANGAT TINGGI\n",
        "# Orange/Merah Muda (15.0-16.5) = Q-value TINGGI\n",
        "# Biru (13.0-14.5) = Q-value RENDAH\n",
        "\n"
      ],
      "metadata": {
        "id": "sWC357zRjJIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}